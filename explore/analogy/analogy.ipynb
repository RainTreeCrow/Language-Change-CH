{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "modeldir = '../../compass/1-year/model-cbow/'\n",
    "models_cbow = []\n",
    "\n",
    "for i in range(1946, 2024):\n",
    "    year = modeldir + str(i) + '.model'\n",
    "    model = Word2Vec.load(year)\n",
    "    models_cbow.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "csv_folder = 'analogy_words'\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(csv_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analogy(models, search_word, search_year):\n",
    "    \"\"\"\n",
    "    Saves the top 10 most similar words for each year into a single CSV file.\n",
    "    \n",
    "    Args:\n",
    "        models (list): List of word2vec models sorted by year.\n",
    "        search_word (str): The word to search for in the models.\n",
    "        search_year (int): The starting year corresponding to the first model in the list.\n",
    "        csv_folder (str): The folder path where the CSV file will be saved.\n",
    "    \"\"\"\n",
    "    # Define the output CSV file path\n",
    "    csv = os.path.join(csv_folder, f\"{search_word}_{search_year}.csv\")\n",
    "    search_word = models_cbow[search_year-1946].wv[search_word]\n",
    "    # Initialize the starting year\n",
    "    year = 1946\n",
    "    # Initialize the data list with headers\n",
    "    headers = ['year'] + [f\"top {i}\" for i in range(1, 11)]\n",
    "    data = []\n",
    "\n",
    "    # Iterate over the models\n",
    "    for model in models:\n",
    "        # Get the top 10 most similar words to the search word\n",
    "        similar_words = [word for word, _ in model.wv.most_similar([search_word], topn=10)]\n",
    "        # Append the year and the list of top 10 words to the data\n",
    "        data.append([year] + similar_words)\n",
    "        year += 1\n",
    "    \n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy(models_cbow, '电脑', 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy(models_cbow, '手机', 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy(models_cbow, 'CD', 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy(models_cbow, '电动车', 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy(models_cbow, '微信', 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy(models_cbow, '微博', 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy(models_cbow, '俄乌', 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy(models_cbow, '新冠', 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In the generated word occurrence .txt file, we manually removed some lines and saved seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def word_occurrence(csv_file):\n",
    "    \"\"\"\n",
    "    Get word occurrences and saves the results to a .txt file.\n",
    "    \n",
    "    Args:\n",
    "        csv_file (str): Path to the CSV file with columns for year and top 1 to top 10 words.\n",
    "    \"\"\"\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Initialize a dictionary to store the occurrences of each word\n",
    "    word_dict = {}\n",
    "    \n",
    "    # Process the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        year = row['year']\n",
    "        for word in row[1:]:  # Assuming columns from index 1 to end are words\n",
    "            if pd.notna(word):  # Check if the word is not NaN\n",
    "                if word in word_dict:\n",
    "                    word_dict[word].append(year)\n",
    "                else:\n",
    "                    word_dict[word] = [year]\n",
    "\n",
    "    # Filter words by the minimum occurrence threshold\n",
    "    filtered_word_dict = {word: years for word, years in word_dict.items()}\n",
    "    \n",
    "    # Prepare the output file name\n",
    "    base_name = os.path.basename(csv_file)\n",
    "    file_name, _ = os.path.splitext(base_name)\n",
    "    output_file = f'{file_name}.txt'\n",
    "    \n",
    "    # Write the filtered word dictionary to the .txt file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for word, years in filtered_word_dict.items():\n",
    "            f.write(f'{word}: {\", \".join(map(str, years))}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "def plot_occurrence(search_words, occurrence, disambiguation):\n",
    "    # Read the occurrence data\n",
    "    word_occurrences = {}\n",
    "    with open(occurrence, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            word, years = line.split(\": \")\n",
    "            years = list(map(int, years.strip('[]\\n').split(',')))\n",
    "            word_occurrences[word] = years\n",
    "\n",
    "    # Read the disambiguation data\n",
    "    disambiguation_dict = {}\n",
    "    with open(disambiguation, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            synonyms = line.strip().split('/')\n",
    "            target_word = synonyms[0]\n",
    "            for synonym in synonyms[1:]:\n",
    "                disambiguation_dict[synonym] = target_word\n",
    "\n",
    "    # Merge occurrences of synonyms to the target words\n",
    "    combined_occurrences = {word: [] for word in search_words.keys()}\n",
    "\n",
    "    for word, years in word_occurrences.items():\n",
    "        target_word = disambiguation_dict.get(word, word)\n",
    "        # Map synonym to target word, or use the original if not found\n",
    "        if target_word in combined_occurrences:\n",
    "            combined_occurrences[target_word].extend(years)\n",
    "\n",
    "    # Remove duplicates and sort the years\n",
    "    for word in combined_occurrences:\n",
    "        combined_occurrences[word] = sorted(set(combined_occurrences[word]))\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(6,4), dpi=200)\n",
    "    this_font = FontProperties(family='Noto Sans SC')  # Set font for Chinese characters\n",
    "\n",
    "    color_list = [\n",
    "        'lightgreen', 'limegreen', 'forestgreen', 'mediumseagreen', 'darkcyan',\n",
    "        'turquoise', 'deepskyblue', 'dodgerblue', 'royalblue', 'darkblue',\n",
    "        'darkslateblue', 'rebeccapurple', 'blueviolet', 'darkmagenta', 'orchid', 'plum'\n",
    "    ]\n",
    "\n",
    "    # Prepare y-ticks\n",
    "    y_len = range(0, len(combined_occurrences) + 2)\n",
    "    \n",
    "    # Modify y_labels to include both key (Chinese) and its value (English translation) correctly\n",
    "    y_labels = [f\"{key} {''.join(search_words.get(key, ''))}\" for key in combined_occurrences.keys()]\n",
    "    y_labels.insert(0, '')  # Add empty labels for padding\n",
    "    y_labels.append('')\n",
    "    \n",
    "    x, y = [], []\n",
    "    # Adjust indexing to avoid KeyError by matching combined_occurrences keys with y_labels without padding\n",
    "    for i, word in enumerate(combined_occurrences.keys(), 1):\n",
    "        for year in combined_occurrences[word]:\n",
    "            x.append(year)\n",
    "            y.append(i)\n",
    "            \n",
    "    # Plot settings\n",
    "    plt.yticks(y_len, y_labels, fontproperties=this_font, fontsize=8)\n",
    "    plt.xlim(1940, 2030)\n",
    "    xticks = list(range(1940, 2035, 10))\n",
    "    plt.xticks(ticks=xticks, labels=[str(year) for year in xticks], fontsize=8)\n",
    "    plt.grid(axis='x', linestyle=':')\n",
    "\n",
    "    # Plot the data points\n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i], y[i], s=10, c=color_list[(y[i] - 1) % len(color_list)])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Prepare the output file name\n",
    "    base_name = os.path.basename(occurrence)\n",
    "    file_name, _ = os.path.splitext(base_name)\n",
    "    output_file = f'{file_name}.png'\n",
    "\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_occurrence('analogy_words/新冠_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_disease = {\n",
    "    \"伤寒\": \"Typhoid Fever\",\n",
    "    \"天花\": \"Smallpox\",\n",
    "    \"白喉\": \"Diphtheria\",\n",
    "    \"鼠疫\": \"Plague\",\n",
    "    \"脑炎\": \"Encephalitis\",\n",
    "    \"痢疾\": \"Dysentery\",\n",
    "    \"百日咳\": \"Whooping Cough\",\n",
    "    \"疟疾\": \"Malaria\",\n",
    "    \"结核\": \"Tuberculosis\",\n",
    "    \"肺炎\": \"Pneumonia\",\n",
    "    \"流感\": \"Influenza\",\n",
    "    \"肝炎\": \"Hepatitis\",\n",
    "    \"艾滋病\": \"AIDS\",\n",
    "    \"禽流感\": \"Avian Influenza\",\n",
    "    \"非典\": \"SARS\",\n",
    "    \"新冠\": \"COVID-19\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_occurrence(search_disease, '新冠_2022.txt', '新冠_merge.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_occurrence('analogy_words/俄乌_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_conflict = {\n",
    "    '美苏': 'US-Soviet/Russia',\n",
    "    '朝鲜': 'North Korea',\n",
    "    '越南': 'Vietnam',\n",
    "    '台湾': 'Taiwan',\n",
    "    '中东': 'Middle East',\n",
    "    '印巴': 'India-Pakistan',\n",
    "    '黎巴嫩': 'Lebanon',\n",
    "    '美伊': 'US-Iraq',\n",
    "    '两伊': 'Iran-Iraq',\n",
    "    '阿以': 'Arab-Israel',\n",
    "    '中美洲': 'Central America',\n",
    "    '阿富汗': 'Afghanistan',\n",
    "    '巴以': 'Palestine-Israel',\n",
    "    '乌克兰': 'Ukraine',\n",
    "    '叙利亚': 'Syria'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_occurrence(search_conflict, '俄乌_2022.txt', '俄乌_merge.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
