{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "modeldir = '../../compass/1-year/model-cbow/'\n",
    "models_cbow = []\n",
    "\n",
    "for i in range(1946, 2024):\n",
    "    year = modeldir + str(i) + '.model'\n",
    "    model = Word2Vec.load(year)\n",
    "    models_cbow.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "csv_folder = 'analogy_words'\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(csv_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analogy(models, search_word, search_year):\n",
    "    \"\"\"\n",
    "    Saves the top 10 most similar words for each year into a single CSV file.\n",
    "    \n",
    "    Args:\n",
    "        models (list): List of word2vec models sorted by year.\n",
    "        search_word (str): The word to search for in the models.\n",
    "        search_year (int): The starting year corresponding to the first model in the list.\n",
    "        csv_folder (str): The folder path where the CSV file will be saved.\n",
    "    \"\"\"\n",
    "    # Define the output CSV file path\n",
    "    csv_file = os.path.join(csv_folder, f\"{search_word}_{search_year}.csv\")\n",
    "    search_word = models_cbow[search_year-1946].wv[search_word]\n",
    "    # Initialize the starting year\n",
    "    year = 1946\n",
    "    # Initialize the data list with headers\n",
    "    headers = ['year'] + [f\"top {i}\" for i in range(1, 11)]\n",
    "    data = []\n",
    "\n",
    "    # Iterate over the models\n",
    "    for model in models:\n",
    "        # Get the top 10 most similar words to the search word\n",
    "        similar_words = [word for word, _ in model.wv.most_similar([search_word], topn=10)]\n",
    "        # Append the year and the list of top 10 words to the data\n",
    "        data.append([year] + similar_words)\n",
    "        year += 1\n",
    "    \n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy(models_cbow, '电脑', 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy(models_cbow, '手机', 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy(models_cbow, 'CD', 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy(models_cbow, '电动车', 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy(models_cbow, '微信', 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy(models_cbow, '微博', 2023)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
