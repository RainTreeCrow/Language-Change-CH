{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csv_file = 'temp_analogy.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians = ['ch_chairman', 'ch_premier', 'us_president', 'us_secretary',\n",
    "               'uk_minister', 'fr_president', 'de_premier', 'jp_premier', 'kr_president']\n",
    "\n",
    "fieldnames = ['model', 'type', 'depth']\n",
    "\n",
    "for politician in politicians:\n",
    "    fieldnames.extend([\n",
    "        f'{politician}_mrr', f'{politician}_mp1', f'{politician}_mp5', f'{politician}_mp10'\n",
    "    ])\n",
    "\n",
    "fieldnames.extend(['total_mrr', 'total_mp1', 'total_mp5', 'total_mp10'])\n",
    "\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "\n",
    "def reciprocal_rank(neighbours, target_words):\n",
    "    for rank, word in enumerate(neighbours, start=1):\n",
    "        if word in target_words:\n",
    "            return 1.0 / rank\n",
    "    # If target word not in 'neighbours', return 0\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def precision(neighbours, target_words, k):\n",
    "    for target_word in target_words:\n",
    "        if target_word in neighbours[:k]:\n",
    "            return 1.0\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def temporal_analogy(models):\n",
    "    analogy_scores_list = []\n",
    "\n",
    "    df = pd.read_csv('facts/politicians.csv')\n",
    "    columns = politicians\n",
    "\n",
    "    for depth in range (5, 85, 5):\n",
    "        reciprocal_all = 0\n",
    "        precision_1_all = 0\n",
    "        precision_5_all = 0\n",
    "        precision_10_all = 0\n",
    "        total_all = 0\n",
    "        analogy_scores = [depth]\n",
    "        for column in columns:\n",
    "            test_pair_num = 0\n",
    "            reciprocal = 0\n",
    "            precision_1 = 0\n",
    "            precision_5 = 0\n",
    "            precision_10 = 0\n",
    "            non_empty_rows = df[df[column].notna()][['year', column]]\n",
    "            \n",
    "            for index, row in non_empty_rows.iterrows():\n",
    "                search_year = row['year']\n",
    "                column_value = row[column]\n",
    "                split_values = column_value.split('/')\n",
    "                if len(split_values) == 1:\n",
    "                    search_word = split_values[0]\n",
    "                    if search_word in models[search_year-1946].wv:\n",
    "                        search_vector = models[search_year-1946].wv[search_word]\n",
    "                        other_rows = non_empty_rows[(non_empty_rows.index != index) & \n",
    "                            (abs(non_empty_rows['year'] - search_year) <= depth) &\n",
    "                            (abs(non_empty_rows['year'] - search_year) > depth - 5)]\n",
    "                        \n",
    "                        if not other_rows.empty:\n",
    "                            for _, other_row in other_rows.iterrows():\n",
    "                                target_year = other_row['year']\n",
    "                                test_pair_num += 1\n",
    "                                other_column_value = other_row[column]\n",
    "                                target_words = other_column_value.split('/')\n",
    "                                predicted = models[target_year-1946].wv.most_similar([search_vector])\n",
    "                                neighbours = [pair[0] for pair in predicted]\n",
    "                                reciprocal += reciprocal_rank(neighbours, target_words)\n",
    "                                precision_1 += precision(neighbours, target_words, 1)\n",
    "                                precision_5 += precision(neighbours, target_words, 5)\n",
    "                                precision_10 += precision(neighbours, target_words, 10)\n",
    "            \n",
    "            if test_pair_num != 0:\n",
    "                reciprocal_all += reciprocal\n",
    "                precision_1_all += precision_1\n",
    "                precision_5_all += precision_5\n",
    "                precision_10_all += precision_10\n",
    "                total_all += test_pair_num\n",
    "                analogy_scores.extend([reciprocal / test_pair_num, \n",
    "                    precision_1 / test_pair_num,\n",
    "                    precision_5 / test_pair_num,\n",
    "                    precision_10 / test_pair_num])\n",
    "            else:\n",
    "                analogy_scores.extend([None, None, None, None])\n",
    "\n",
    "        if total_all != 0:\n",
    "            analogy_scores.extend([reciprocal_all / total_all,\n",
    "                precision_1_all / total_all,\n",
    "                precision_5_all / total_all,\n",
    "                precision_10_all / total_all])\n",
    "        else:\n",
    "            analogy_scores.extend([None, None, None, None])\n",
    "\n",
    "        analogy_scores_list.append(analogy_scores)\n",
    "    \n",
    "    return analogy_scores_list\n",
    "\n",
    "\n",
    "def temp_ana_eval(models, m_name, m_type):\n",
    "    for scores in temporal_analogy(models):\n",
    "        row = [m_name, m_type]\n",
    "        row.extend(scores)\n",
    "        \n",
    "        with open(csv_file, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def draw_graph():\n",
    "    df = pd.read_csv('temp_analogy.csv')\n",
    "\n",
    "    combinations = df[['model', 'type']].drop_duplicates()\n",
    "    columns = politicians + ['total']\n",
    "\n",
    "    for column in columns:\n",
    "        fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "\n",
    "        for index, row in combinations.iterrows():\n",
    "            model_name = row['model']\n",
    "            model_type = row['type']\n",
    "            subset = df[(df['model'] == model_name) & (df['type'] == model_type)]\n",
    "            subset = subset.sort_values(by='depth')\n",
    "\n",
    "            axes[0][0].plot(subset['depth'], subset[column + '_mrr'], label=f'{model_name}-{model_type}')\n",
    "            axes[0][0].set_title('Analogy ' + column + ' MRR')\n",
    "            axes[0][0].set_xlabel('depth')\n",
    "            axes[0][0].set_ylabel('Mean Reciprocal Rank')\n",
    "            \n",
    "            axes[0][1].plot(subset['depth'], subset[column + '_mp1'], label=f'{model_name}-{model_type}')\n",
    "            axes[0][1].set_title('Analogy ' + column + ' MP@1')\n",
    "            axes[0][1].set_xlabel('depth')\n",
    "            axes[0][1].set_ylabel('Mean Precision @ 1')\n",
    "\n",
    "            axes[1][0].plot(subset['depth'], subset[column + '_mp5'], label=f'{model_name}-{model_type}')\n",
    "            axes[1][0].set_title('Analogy ' + column + ' MP@5')\n",
    "            axes[1][0].set_xlabel('depth')\n",
    "            axes[1][0].set_ylabel('Mean Precision @ 5')\n",
    "\n",
    "            axes[1][1].plot(subset['depth'], subset[column + '_mp10'], label=f'{model_name}-{model_type}')\n",
    "            axes[1][1].set_title('Analogy ' + column + ' MP@10')\n",
    "            axes[1][1].set_xlabel('depth')\n",
    "            axes[1][1].set_ylabel('Mean Precision @ 10')\n",
    "        \n",
    "        axes[0][0].legend()\n",
    "        axes[0][1].legend()\n",
    "        axes[1][0].legend()\n",
    "        axes[1][1].legend()\n",
    "        fig.tight_layout()\n",
    "        plt.savefig('graphic/' + column + '.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldir = '../../compass/1-year/model-sgns/'\n",
    "models_sgns = []\n",
    "\n",
    "for i in range(1946, 2024):\n",
    "    year = modeldir + str(i) + '.model'\n",
    "    model = Word2Vec.load(year)\n",
    "    models_sgns.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ana_eval(models_sgns, 'compass', 'sgns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldir = '../../compass/1-year/model-cbow/'\n",
    "models_cbow = []\n",
    "\n",
    "for i in range(1946, 2024):\n",
    "    year = modeldir + str(i) + '.model'\n",
    "    model = Word2Vec.load(year)\n",
    "    models_cbow.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ana_eval(models_cbow, 'compass', 'cbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw all politicians on the same graph for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_compare():\n",
    "    df = pd.read_csv('temp_analogy.csv')\n",
    "\n",
    "    # Filter data for the specified model and type\n",
    "    df_filtered = df[(df['model'] == 'compass') & (df['type'] == 'cbow')]\n",
    "\n",
    "    # Define the columns to plot (politicians)\n",
    "    columns = ['ch_chairman', 'ch_premier', 'us_president', 'us_secretary',\n",
    "                   'uk_minister', 'fr_president', 'de_premier', 'jp_premier', 'kr_president']\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "\n",
    "    # Iterate over metrics to create subplots\n",
    "    metrics = ['mrr', 'mp1', 'mp5', 'mp10']\n",
    "    titles = ['Analogy MRR', 'Analogy MP@1', 'Analogy MP@5', 'Analogy MP@10']\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axes[i // 2][i % 2]\n",
    "        for col in columns:\n",
    "            subset = df_filtered.sort_values(by='depth')\n",
    "            ax.plot(subset['depth'], subset[f'{col}_{metric}'], label=col)\n",
    "        \n",
    "        ax.set_title(titles[i])\n",
    "        ax.set_xlabel('depth')\n",
    "        ax.set_ylabel('Mean Reciprocal Rank' if metric == 'mrr' else f'Mean Precision @ {metric[-1]}')\n",
    "        ax.legend()\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.savefig('compare.png')\n",
    "    plt.close()\n",
    "\n",
    "# Run the function\n",
    "draw_compare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the frequency of politician names each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Paths to the files and folders\n",
    "politicians_file = 'facts/politicians.csv'\n",
    "frequency_folder = '../../corpus/frequency'\n",
    "output_file = 'politician_freq.csv'\n",
    "\n",
    "# Read the politicians CSV file\n",
    "politicians_df = pd.read_csv(politicians_file, encoding='utf-8')\n",
    "\n",
    "# Get a list of all years from the politicians CSV file\n",
    "years = politicians_df['year'].tolist()\n",
    "\n",
    "columns = ['ch_chairman', 'ch_premier', 'us_president', 'us_secretary', \n",
    "           'uk_minister', 'fr_president', 'de_premier', 'jp_premier', 'kr_president']\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "result = {'year': years}\n",
    "\n",
    "# Add the other columns\n",
    "for col in columns:\n",
    "    result[col] = []\n",
    "\n",
    "# Iterate over each year\n",
    "for year in years:\n",
    "    # Path to the frequency file for the current year\n",
    "    frequency_file = os.path.join(frequency_folder, f'{year}.txt')\n",
    "    # Initialize a dictionary to store frequencies for each politician\n",
    "    year_counts = {col: 0 for col in columns}\n",
    "\n",
    "    # If the frequency file exists for the current year\n",
    "    if os.path.exists(frequency_file):\n",
    "        with open(frequency_file, 'r', encoding='utf-8') as file:\n",
    "            # Read the frequency data into a dictionary\n",
    "            frequency_data = {}\n",
    "            for line in file:\n",
    "                word, count = line.strip().split()\n",
    "                frequency_data[word] = int(count)\n",
    "        \n",
    "        # Process each politician category\n",
    "        for col in columns:\n",
    "            # Get the list of names for the current politician category\n",
    "            names = politicians_df.loc[politicians_df['year'] == year, col].values[0]\n",
    "\n",
    "            # If the names are NaN, keep the count as NaN\n",
    "            if pd.isna(names):\n",
    "                year_counts[col] = None\n",
    "            else:\n",
    "                names = names.split('/')  # Handle multiple names separated by '/'\n",
    "                # Sum the counts for each name in the frequency data\n",
    "                for name in names:\n",
    "                    if name in frequency_data:\n",
    "                        year_counts[col] += frequency_data[name]\n",
    "    \n",
    "    # Append the results for the current year to the result dictionary\n",
    "    for col in columns:\n",
    "        result[col].append(year_counts[col])\n",
    "\n",
    "average_row = []\n",
    "\n",
    "for col in columns:\n",
    "    # Calculate the average, excluding NaN values\n",
    "    values = [val for val in result[col] if pd.notna(val)]\n",
    "    average = sum(values) / len(values) if values else 0\n",
    "    average_row.append(average)\n",
    "\n",
    "# Add the average row to the result\n",
    "result['year'].append('average')  # Add a label for the average row\n",
    "\n",
    "for i, col in enumerate(columns):\n",
    "    result[col].append(average_row[i])\n",
    "\n",
    "# Convert the result dictionary to a DataFrame and save it as a CSV file\n",
    "result_df = pd.DataFrame(result)\n",
    "result_df.to_csv(output_file, index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
