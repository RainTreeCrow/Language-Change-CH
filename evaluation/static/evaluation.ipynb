{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing quality of static (compass) word embeddings (similarity task and analogy task) and temporal (target) embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csv_file = 'static_eval.csv'\n",
    "fieldnames = ['model', 'type', 'slice', '240', '297',\n",
    "    'capital_mrr', 'capital_mp1', 'capital_mp5', 'capital_mp10',\n",
    "    'city_mrr', 'city_mp1', 'city_mp5', 'city_mp10',\n",
    "    'family_mrr', 'family_mp1', 'family_mp5', 'family_mp10',\n",
    "    'total_mmr', 'total_mp1', 'total_mp5', 'total_mp10']\n",
    "\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "\n",
    "def cosine_sim(x,y):\n",
    "    num = np.dot(x, y)\n",
    "    denom = np.linalg.norm(x) * np.linalg.norm(y)\n",
    "    return num / denom\n",
    "\n",
    "\n",
    "def word_sim(model):\n",
    "    sim_scores = []\n",
    "\n",
    "    for sim in ['240', '297']:\n",
    "        file = open('word_sim/' + sim + '.txt', 'r', encoding='utf-8')\n",
    "        test_pair_num = 0\n",
    "        skip_pair_num = 0\n",
    "        word_sim_std = []\n",
    "        word_sim_pre = []\n",
    "        for line in file:\n",
    "            word1, word2, val_str = line.strip().split()[0:3]\n",
    "            if word1 in model.wv and word2 in model.wv:\n",
    "                test_pair_num += 1\n",
    "                word_sim_std.append(float(val_str))\n",
    "                word_vec1 = model.wv[word1]\n",
    "                word_vec2 = model.wv[word2]\n",
    "                cos_sim = cosine_sim(word_vec1, word_vec2)\n",
    "                word_sim_pre.append(cos_sim)\n",
    "            else:\n",
    "                skip_pair_num += 1\n",
    "                # print('Skip:', word1, word2)\n",
    "\n",
    "        spear_coef, _ = stats.spearmanr(word_sim_std, word_sim_pre)\n",
    "        sim_scores.append(spear_coef)\n",
    "\n",
    "    return sim_scores\n",
    "\n",
    "\n",
    "def reciprocal_rank(neighbours, target_word):\n",
    "    for rank, word in enumerate(neighbours, start=1):\n",
    "        if word == target_word:\n",
    "            return 1.0 / rank\n",
    "    # If target word not in 'neighbours', return 0\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def precision(neighbours, target_word, k):\n",
    "    if target_word in neighbours[:k]:\n",
    "        return 1.0\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def word_analogy(model):\n",
    "    reciprocal_all = 0\n",
    "    precision_1_all = 0\n",
    "    precision_5_all = 0\n",
    "    precision_10_all = 0\n",
    "    total_all = 0\n",
    "    analogy_scores = []\n",
    "\n",
    "    for ana in ['capital', 'city', 'family']:\n",
    "        file = open('word_analogy/' + ana + '.txt', 'r', encoding='utf-8')\n",
    "        test_pair_num = 0\n",
    "        reciprocal = 0\n",
    "        precision_1 = 0\n",
    "        precision_5 = 0\n",
    "        precision_10 = 0\n",
    "        for line in file:\n",
    "            word1, word2, word3, word4 = line.strip().split()[0:4]\n",
    "            if word1 in model.wv and word2 in model.wv and word3 in model.wv:\n",
    "                test_pair_num += 1\n",
    "                predicted = model.wv.most_similar(positive=[word2, word3], negative=[word1])\n",
    "                neighbours = [pair[0] for pair in predicted]\n",
    "                reciprocal += reciprocal_rank(neighbours, word4)\n",
    "                precision_1 += precision(neighbours, word4, 1)\n",
    "                precision_5 += precision(neighbours, word4, 5)\n",
    "                precision_10 += precision(neighbours, word4, 10)\n",
    "        \n",
    "        reciprocal_all += reciprocal\n",
    "        precision_1_all += precision_1\n",
    "        precision_5_all += precision_5\n",
    "        precision_10_all += precision_10\n",
    "        total_all += test_pair_num\n",
    "        analogy_scores.extend([reciprocal / test_pair_num, \n",
    "            precision_1 / test_pair_num,\n",
    "            precision_5 / test_pair_num,\n",
    "            precision_10 / test_pair_num])\n",
    "    \n",
    "    analogy_scores.extend([reciprocal_all / total_all,\n",
    "        precision_1_all / total_all,\n",
    "        precision_5_all / total_all,\n",
    "        precision_10_all / total_all])\n",
    "    \n",
    "    return analogy_scores\n",
    "\n",
    "\n",
    "def static_eval(model, m_name, m_type, m_slice):\n",
    "    row = [m_name, m_type, m_slice]\n",
    "    row.extend(word_sim(model))\n",
    "    row.extend(word_analogy(model))\n",
    "    \n",
    "    with open(csv_file, 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_type in ['sgns', 'cbow']:\n",
    "    for year_slice in ['compass', '1954-1978', '1979-2003']:\n",
    "        model_path = '../../compass/2-slices/model-' + model_type + '/' + year_slice + '.model'\n",
    "        model = Word2Vec.load(model_path)\n",
    "        static_eval(model, 'compass', model_type, year_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the quality of HistWord style train-aligned embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_type in ['sgns', 'cbow']:\n",
    "    for year_slice in ['1954-1978', '1979-2003']:\n",
    "        model_path = '../../alignment/2-slices/model-' + model_type + '/' + year_slice + '.model'\n",
    "        model = Word2Vec.load(model_path)\n",
    "        static_eval(model, 'alignment', model_type, year_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the quality of 5-year slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('1-year/alignment.txt', 'w', encoding='utf-8')\n",
    "f.write('Testing alignment based Word2Vec\\n')\n",
    "f.write('===========================\\n')\n",
    "\n",
    "for i in range(1946, 2024):\n",
    "    f.write('Slice ' + str(i) + '\\n')\n",
    "    f.write('---------------\\n')\n",
    "    model_path = '../../alignment/1-year/model/' + str(i) + '.model'\n",
    "    model = Word2Vec.load(model_path)\n",
    "    word_sim(model, f)\n",
    "    f.write('---------------\\n')\n",
    "    word_analogy(model, f)\n",
    "    f.write('...........................\\n')\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
