{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing temporal word embeddings against the ChiWUG COMPARE score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "df = pd.read_csv('chi_wug/stats_groupings.csv', sep='\\t')\n",
    "\n",
    "lemma = df[['lemma', 'COMPARE']].to_records(index=False).tolist()\n",
    "lemma = sorted(lemma, key=lambda x: x[1])\n",
    "\n",
    "\n",
    "def cosine_sim(x,y):\n",
    "    num = np.dot(x, y)\n",
    "    denom = np.linalg.norm(x) * np.linalg.norm(y)\n",
    "    return num / denom\n",
    "\n",
    "\n",
    "def word_compare(model1, model2, lemma, f):\n",
    "    word_compare_std = []\n",
    "    word_compare_pre = []\n",
    "    for word, COMPARE in lemma:\n",
    "        if word in model1.wv.vocab and word in model2.wv.vocab:\n",
    "            word_compare_std.append(float(COMPARE))\n",
    "            word_vec1 = model1.wv[word]\n",
    "            word_vec2 = model2.wv[word]\n",
    "            cos_sim = cosine_sim(word_vec1, word_vec2)\n",
    "            word_compare_pre.append(cos_sim)\n",
    "            if f is not None:\n",
    "                f.write(word.ljust(6, ' ') + f'{COMPARE:.5f}   {cos_sim:.5f}\\n')\n",
    "        else:\n",
    "            print('Skip:', word)\n",
    "    \n",
    "    spear_coef, p_value = stats.spearmanr(word_compare_std, word_compare_pre)\n",
    "    print(\"Spearman Score: \" + str(spear_coef))\n",
    "    print(\"P value: \", str(p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sgns based Word2Vec\n",
      "===========================\n",
      "Spearman Score: 0.40328408334518023\n",
      "P value:  0.009870551741013287\n",
      "...........................\n",
      "Testing cbow based Word2Vec\n",
      "===========================\n",
      "Spearman Score: 0.31630308165579396\n",
      "P value:  0.04676514067721062\n",
      "...........................\n"
     ]
    }
   ],
   "source": [
    "for model_type in ['sgns', 'cbow']:\n",
    "    print('Testing ' + model_type + ' based Word2Vec')\n",
    "    print('===========================')\n",
    "    model_path_before = '../../compass/2-slices/model-' + model_type + '/1954-1978.model'\n",
    "    model_before = Word2Vec.load(model_path_before)\n",
    "    model_path_after = '../../compass/2-slices/model-' + model_type + '/1979-2003.model'\n",
    "    model_after = Word2Vec.load(model_path_after)\n",
    "    f = open('chi_wug/compass-' + model_type + '.txt', 'w', encoding='utf-8')\n",
    "    word_compare(model_before, model_after, lemma, f)\n",
    "    f.close()\n",
    "    print('...........................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sgns based Word2Vec\n",
      "===========================\n",
      "Spearman Score: 0.4182031548323565\n",
      "P value:  0.007244593660021611\n",
      "...........................\n",
      "Testing cbow based Word2Vec\n",
      "===========================\n",
      "Spearman Score: 0.48257097269526794\n",
      "P value:  0.001612647685297571\n",
      "...........................\n"
     ]
    }
   ],
   "source": [
    "for model_type in ['sgns', 'cbow']:\n",
    "    print('Testing ' + model_type + ' based Word2Vec')\n",
    "    print('===========================')\n",
    "    model_path_before = '../../alignment/2-slices/model-' + model_type + '/1954-1978.model'\n",
    "    model_before = Word2Vec.load(model_path_before)\n",
    "    model_path_after = '../../alignment/2-slices/model-' + model_type + '/1979-2003.model'\n",
    "    model_after = Word2Vec.load(model_path_after)\n",
    "    f = open('chi_wug/alignment-' + model_type + '.txt', 'w', encoding='utf-8')\n",
    "    word_compare(model_before, model_after, lemma, f)\n",
    "    f.close()\n",
    "    print('...........................')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model works especially unwell with one-character \"words\", this may be due to the nature of Chinese (that boundary between characters and words can be obscure). Therefore, we also try removing one-character test examples and test the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sgns based Word2Vec\n",
      "===========================\n",
      "Spearman Score: 0.6780776613193285\n",
      "P value:  7.338397139077492e-05\n",
      "...........................\n",
      "Testing cbow based Word2Vec\n",
      "===========================\n",
      "Spearman Score: 0.626044238197086\n",
      "P value:  0.0003660212465805694\n",
      "...........................\n"
     ]
    }
   ],
   "source": [
    "lemma_no_ch = [pair for pair in lemma if len(pair[0]) > 1]\n",
    "\n",
    "for model_type in ['sgns', 'cbow']:\n",
    "    print('Testing ' + model_type + ' based Word2Vec')\n",
    "    print('===========================')\n",
    "    model_path_before = '../../compass/2-slices/model-' + model_type + '/1954-1978.model'\n",
    "    model_before = Word2Vec.load(model_path_before)\n",
    "    model_path_after = '../../compass/2-slices/model-' + model_type + '/1979-2003.model'\n",
    "    model_after = Word2Vec.load(model_path_after)\n",
    "    word_compare(model_before, model_after, lemma_no_ch, None)\n",
    "    print('...........................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sgns based Word2Vec\n",
      "===========================\n",
      "Spearman Score: 0.7240861617642587\n",
      "P value:  1.3263676117849011e-05\n",
      "...........................\n",
      "Testing cbow based Word2Vec\n",
      "===========================\n",
      "Spearman Score: 0.7101192955577621\n",
      "P value:  2.3065946929965612e-05\n",
      "...........................\n"
     ]
    }
   ],
   "source": [
    "for model_type in ['sgns', 'cbow']:\n",
    "    print('Testing ' + model_type + ' based Word2Vec')\n",
    "    print('===========================')\n",
    "    model_path_before = '../../alignment/2-slices/model-' + model_type + '/1954-1978.model'\n",
    "    model_before = Word2Vec.load(model_path_before)\n",
    "    model_path_after = '../../alignment/2-slices/model-' + model_type + '/1979-2003.model'\n",
    "    model_after = Word2Vec.load(model_path_after)\n",
    "    word_compare(model_before, model_after, lemma_no_ch, None)\n",
    "    print('...........................')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we test the one-character examples only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sgns based Word2Vec\n",
      "===========================\n",
      "Spearman Score: 0.027972027972027972\n",
      "P value:  0.9312343512018808\n",
      "...........................\n",
      "Testing cbow based Word2Vec\n",
      "===========================\n",
      "Spearman Score: 0.21678321678321683\n",
      "P value:  0.49855598552418856\n",
      "...........................\n"
     ]
    }
   ],
   "source": [
    "lemma_only_ch = [pair for pair in lemma if len(pair[0]) == 1]\n",
    "\n",
    "for model_type in ['sgns', 'cbow']:\n",
    "    print('Testing ' + model_type + ' based Word2Vec')\n",
    "    print('===========================')\n",
    "    model_path_before = '../../compass/2-slices/model-' + model_type + '/1954-1978.model'\n",
    "    model_before = Word2Vec.load(model_path_before)\n",
    "    model_path_after = '../../compass/2-slices/model-' + model_type + '/1979-2003.model'\n",
    "    model_after = Word2Vec.load(model_path_after)\n",
    "    word_compare(model_before, model_after, lemma_only_ch, None)\n",
    "    print('...........................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sgns based Word2Vec\n",
      "===========================\n",
      "Spearman Score: -0.06293706293706294\n",
      "P value:  0.8459309212287789\n",
      "...........................\n",
      "Testing cbow based Word2Vec\n",
      "===========================\n",
      "Spearman Score: 0.18181818181818185\n",
      "P value:  0.5717012385276553\n",
      "...........................\n"
     ]
    }
   ],
   "source": [
    "lemma_only_ch = [pair for pair in lemma if len(pair[0]) == 1]\n",
    "\n",
    "for model_type in ['sgns', 'cbow']:\n",
    "    print('Testing ' + model_type + ' based Word2Vec')\n",
    "    print('===========================')\n",
    "    model_path_before = '../../alignment/2-slices/model-' + model_type + '/1954-1978.model'\n",
    "    model_before = Word2Vec.load(model_path_before)\n",
    "    model_path_after = '../../alignment/2-slices/model-' + model_type + '/1979-2003.model'\n",
    "    model_after = Word2Vec.load(model_path_after)\n",
    "    word_compare(model_before, model_after, lemma_only_ch, None)\n",
    "    print('...........................')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
