{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import jieba\n",
    "\n",
    "stopfile = '../../corpus/stopwords.txt'\n",
    "sentdir = '../../corpus/sent/'\n",
    "yearlydir = '../../corpus/1-year/'\n",
    "frequencydir = '../../corpus/frequency/'\n",
    "wordcountdir = '../../corpus/wordcount.txt'\n",
    "\n",
    "with open(stopfile, 'r', encoding='utf-8') as sf:\n",
    "    stopword_list = [word.strip('\\n') for word in sf.readlines()]\n",
    "\n",
    "for newdir in [yearlydir, frequencydir]:\n",
    "    if not os.path.exists(newdir):\n",
    "        os.makedirs(newdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_and_write(inputdir, outputdir, countdir):\n",
    "    counts = {}\n",
    "    total_word_count = 0\n",
    "    with open(inputdir, 'r', encoding='utf-8') as infile, open(outputdir, 'w', encoding='utf-8') as outfile:\n",
    "        for line in infile:\n",
    "            sentence = line.strip()\n",
    "            if sentence:\n",
    "                temp = \"\"\n",
    "                for word in jieba.lcut(sentence):\n",
    "                    if not (re.search('[^\\.\\-0-9a-zA-Z\\u4e00-\\u9fa5]+', word) or re.match('[\\.\\-\\d]+', word)):\n",
    "                        if word not in stopword_list:\n",
    "                            temp += word + \" \"\n",
    "                            total_word_count += 1\n",
    "                            if word in counts.keys():\n",
    "                                counts[word] = counts[word] + 1\n",
    "                            else:\n",
    "                                counts[word] = 1\n",
    "                temp = temp.strip()\n",
    "                if temp:\n",
    "                    outfile.write(temp + '\\n')\n",
    "    \n",
    "    counts_list = list(counts.items())\n",
    "    counts_list.sort(key=lambda x:x[1], reverse=True)\n",
    "\n",
    "    with open(countdir, 'w', encoding='utf-8') as countfile:\n",
    "        for (word, freq) in counts_list:\n",
    "            word_freq = word + ' ' + str(freq) + '\\n'\n",
    "            countfile.write(word_freq)\n",
    "    \n",
    "    return total_word_count\n",
    "\n",
    "\n",
    "def process_all_years(input_folder, output_folder, count_folder):\n",
    "    year_count = {}\n",
    "    for filename in os.listdir(input_folder):\n",
    "        year = filename.split('.')[0]\n",
    "        input_file = os.path.join(input_folder, filename)\n",
    "        output_file = os.path.join(output_folder, f'{year}.txt')\n",
    "        count_file = os.path.join(count_folder, f'{year}.txt')\n",
    "        year_count[year] = segment_and_write(input_file, output_file, count_file)\n",
    "    \n",
    "    with open(wordcountdir, 'w', encoding='utf-8') as wordcountfile:\n",
    "        for year, count in year_count.items():\n",
    "            wordcountfile.write(year + ' ' + str(count) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_all_years(sentdir, yearlydir, frequencydir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
